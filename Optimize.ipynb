{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import gym\n",
    "import numpy as np\n",
    "import random\n",
    "from q_learning_oop import *\n",
    "from IPython.display import clear_output\n",
    "from test_runner import *\n",
    "\n",
    "frozen_lake_env = gym.make(\"FrozenLake-v0\").env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_params(trial):\n",
    "    \"\"\"\n",
    "    Learning hyperparamters we want to optimize\n",
    "    \"\"\"\n",
    "    return {\n",
    "          \"alpha\": trial.suggest_uniform(\"alpha\", 0.2, 0.3),\n",
    "          \"gamma\": trial.suggest_uniform(\"gamma\", 0.8, 0.999),\n",
    "          \"min_epsilon\": trial.suggest_uniform(\"min_epsilon\", 0.01, 0.1),\n",
    "          \"epsilon_decay\": trial.suggest_uniform(\"epsilon_decay\", 0.8, 0.99999)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \"\"\"\n",
    "    Define an objective function to be minimized.\n",
    "    \"\"\"\n",
    "    model_params = get_model_params(trial)\n",
    "    agent = QLearningAgent(frozen_lake_env, epsilon=1, **model_params)\n",
    "    train_runner = TrainRunner(frozen_lake_env, agent)\n",
    "    train_runner.train(episodes=5000, steps_per_episode=100)\n",
    "    tester = TestRunner(frozen_lake_env, agent)\n",
    "    test_results = tester.test(1000)\n",
    "    return test_results.bad  # A objective value linked with the Trial object.\n",
    "\n",
    "study = optuna.create_study()  # Create a new study.\n",
    "optuna.logging.disable_default_handler()\n",
    "study.optimize(objective, n_trials=500, n_jobs=-1)  # Invoke optimization of the objective function.\n",
    "print(f\"best params:\\n\\t{study.best_params}\")\n",
    "print(f\"trials = {len(study.trials)}\")\n",
    "print(f\"best value: {study.best_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = QLearningAgent(frozen_lake_env, epsilon=1, **study.best_params)\n",
    "train_runner = TrainRunner(frozen_lake_env, agent)\n",
    "train_runner.train(episodes=5000, steps_per_episode=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tester = TestRunner(frozen_lake_env, agent)\n",
    "test_results = tester.test(1000)\n",
    "print(f\"Results after {1000} episodes:\")\n",
    "print(f\"good = {test_results.good}\")\n",
    "print(f\"bad = {test_results.bad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
